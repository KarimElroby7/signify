{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjrePJ5RJm6l",
        "outputId": "d93d74ce-dbf0-41ef-86a4-26f7d6e22d9b"
      },
      "outputs": [],
      "source": [
        "!rm -vr ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "!chmod 777 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from ultralytics import YOLO\n",
        "# from roboflow import Roboflow\n",
        "# rf = Roboflow(api_key=\"rEI3w1C5xkPJcmefNDI3\")\n",
        "# project = rf.workspace(\"sign-arabic-language\").project(\"final-project-kpbmm\")\n",
        "# version = project.version(5)\n",
        "# dataset = version.download(\"yolov8\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uymzXeQPJm6m"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAr_1kSpLShi",
        "outputId": "3788f8b4-39db-4489-98d2-26a1d36e2816"
      },
      "outputs": [],
      "source": [
        "api_token = {\"username\":\"azzaali\",\"key\":\"77d4f57492eab11f39f0a5babfc0ed29\"}\n",
        "import json\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "   json.dump(api_token, file)\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "# !/bin/bash\n",
        "!kaggle datasets download -d ammarsayedtaha/arabic-sign-language-dataset-2022\n",
        "# %%capture\n",
        "!unzip /content/arabic-sign-language-dataset-2022.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPhnLkXkJm6m"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VF4d2f3xJm6o"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUKQq7SBJm6o"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i9gnJ3HqJm6p",
        "outputId": "c7ef41cb-f8c1-4f10-fc67-e8d23baf6819"
      },
      "outputs": [],
      "source": [
        "# def read_labels(label_path):\n",
        "#     with open(label_path, 'r') as file:\n",
        "#         lines = file.readlines()\n",
        "#         labels = [line.strip().split() for line in lines]\n",
        "#     return labels\n",
        "\n",
        "# def draw_boxes(image, labels):\n",
        "#     for label in labels:\n",
        "#         class_id = int(label[0])\n",
        "#         x, y, w, h = map(float, label[1:])\n",
        "#         image_height, image_width, _ = image.shape\n",
        "#         x1 = int((x - w / 2) * image_width)\n",
        "#         y1 = int((y - h / 2) * image_height)\n",
        "#         x2 = int((x + w / 2) * image_width)\n",
        "#         y2 = int((y + h / 2) * image_height)\n",
        "#         color = (0, 255, 0)  # Green\n",
        "#         cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)\n",
        "#     return image\n",
        "\n",
        "# data_dir = '/content/datasets/train'\n",
        "\n",
        "# image_files = [file for file in os.listdir(os.path.join(data_dir, 'images')) if file.endswith('.jpg')]\n",
        "\n",
        "# random.shuffle(image_files)\n",
        "\n",
        "# fig, axes = plt.subplots(3, 3, figsize=(12, 12))\n",
        "# for ax, image_file in zip(axes.ravel(), image_files[:9]):\n",
        "#     image_path = os.path.join(data_dir, 'images', image_file)\n",
        "#     label_path = os.path.join(data_dir, 'labels', os.path.splitext(image_file)[0] + '.txt')\n",
        "\n",
        "#     # Read image\n",
        "#     image = cv2.imread(image_path)\n",
        "#     image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "#     # Read labels\n",
        "#     labels = read_labels(label_path)\n",
        "\n",
        "#     # Draw bounding boxes on the image\n",
        "#     image_with_boxes = draw_boxes(image_rgb, labels)\n",
        "\n",
        "#     # Display image with bounding boxes and set the labels as titles\n",
        "#     ax.imshow(image_with_boxes)\n",
        "#     ax.set_title(str(labels[0][0]))\n",
        "#     ax.axis('off')\n",
        "\n",
        "# plt.tight_layout()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tRj02ktJm6p"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DXaCqYBJm6p",
        "outputId": "735af76e-a831-444e-cffc-dbfc9ebceed4"
      },
      "outputs": [],
      "source": [
        "model = YOLO('yolov8l.yaml')\n",
        "model = YOLO('yolov8l.pt')\n",
        "model = YOLO('yolov8l.yaml').load('yolov8l.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6Xc3TZrJm6q",
        "outputId": "6e7139a2-ac26-4d13-ef04-5c9a20d27f68"
      },
      "outputs": [],
      "source": [
        "history = model.train(data='/content/datasets/sign.yaml', epochs=100, imgsz=640,\n",
        "                    patience = 100, batch = 64,\n",
        "                    project =\"ASL\", optimizer = 'Adam', momentum = 0.9,\n",
        "                    cos_lr=True ,seed = 42, plots = True , close_mosaic = 0, lr0 = 0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vHHVZl1Jm6r"
      },
      "source": [
        "## Loading Model (Previously Trained Model Saved)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kPU9p4kJm6r"
      },
      "outputs": [],
      "source": [
        "# # loading Model\n",
        "# trained_model = YOLO('ASL.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fT6Dc5n5Jm6s"
      },
      "source": [
        "## Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xV5x11DuJm6s"
      },
      "outputs": [],
      "source": [
        "test_images_dir = '/content/datasets/valid/images'\n",
        "test_images = [os.path.join(test_images_dir, image) for image in os.listdir(test_images_dir)]\n",
        "\n",
        "test_samples = np.random.choice(test_images, 10, replace=False)\n",
        "\n",
        "print(test_samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YrYQQrcRJm6s"
      },
      "outputs": [],
      "source": [
        "results = model([test_samples[0], test_samples[1], test_samples[2], test_samples[3], test_samples[4], test_samples[5], test_samples[6], test_samples[7], test_samples[8], test_samples[9]])\n",
        "\n",
        "results_dir = \"results_tries\"\n",
        "if not os.path.exists(results_dir):\n",
        "    os.makedirs(results_dir)\n",
        "\n",
        "i = 0\n",
        "for result in results:\n",
        "    boxes = result.boxes\n",
        "    masks = result.masks\n",
        "    keypoints = result.keypoints\n",
        "    probs = result.probs\n",
        "\n",
        "    # Save image\n",
        "    filename = os.path.join(results_dir, f\"result_{i}.jpg\")\n",
        "    result.save(filename=filename)\n",
        "    # result.show() # Uncomment to display image\n",
        "    i+=1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UeCkRa-7Jm6s"
      },
      "outputs": [],
      "source": [
        "directory = \"results_tries\"\n",
        "\n",
        "images = []\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".jpg\"):\n",
        "        img = plt.imread(os.path.join(directory, filename))\n",
        "        images.append(img)\n",
        "\n",
        "fig, axs = plt.subplots(2, 5, figsize=(50, 25))\n",
        "for i in range(10):\n",
        "    axs[i//5, i%5].imshow(images[i])\n",
        "    axs[i//5, i%5].axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3T235ffBJm6t"
      },
      "source": [
        "## Inference (Use this code when you have your saved trained model + a webcam to capture the frames)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBDjsvm8Jm6t"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# from ultralytics import YOLO\n",
        "\n",
        "# # Load the model\n",
        "# model = YOLO('ASL.pt') # Your saved model's name\n",
        "\n",
        "# # Open the camera\n",
        "# cap = cv2.VideoCapture(0)\n",
        "\n",
        "# # Setting width and height of the video\n",
        "# cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1920)\n",
        "# cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 1080)\n",
        "\n",
        "\n",
        "# while cap.isOpened():\n",
        "\n",
        "#     success, frame = cap.read()\n",
        "\n",
        "#     if success:\n",
        "\n",
        "#         results = model.track(frame, persist=True)\n",
        "\n",
        "\n",
        "#         annotated_frame = results[0].plot()\n",
        "\n",
        "#         cv2.imshow(\"ASL Tracking\", annotated_frame)\n",
        "\n",
        "#         # Break the loop if 'q' is pressed\n",
        "#         if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
        "#             break\n",
        "#     else:\n",
        "#         # Break the loop if\n",
        "#         break\n",
        "\n",
        "# cap.release()\n",
        "# cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 2110872,
          "sourceId": 3508088,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30698,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
